{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11096864,"sourceType":"datasetVersion","datasetId":6917494}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import transforms, datasets\nfrom torch.utils.data import DataLoader\nfrom transformers import DeiTFeatureExtractor, DeiTForImageClassification\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv1D, LSTM, Dense, Dropout, MaxPooling1D, Flatten, BatchNormalization\nfrom tensorflow.keras.models import Model\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T15:20:15.080394Z","iopub.execute_input":"2025-04-01T15:20:15.080588Z","iopub.status.idle":"2025-04-01T15:20:35.821393Z","shell.execute_reply.started":"2025-04-01T15:20:15.080568Z","shell.execute_reply":"2025-04-01T15:20:35.820611Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# Set parameters\nimg_height, img_width = 224, 224\nnum_classes = 7\nbatch_size = 16\nepochs = 25","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T15:20:35.822465Z","iopub.execute_input":"2025-04-01T15:20:35.822900Z","iopub.status.idle":"2025-04-01T15:20:35.826566Z","shell.execute_reply.started":"2025-04-01T15:20:35.822871Z","shell.execute_reply":"2025-04-01T15:20:35.825646Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\n\n# Define parameters\nimg_height = 224\nimg_width = 224\n\n\n# Load datasets\ntrain_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    '/kaggle/input/speechemomel/Melspectro/train',\n    image_size=(img_height, img_width),\n    batch_size=batch_size,\n    shuffle=True\n)\n\ntest_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n    '/kaggle/input/speechemomel/Melspectro/test',\n    image_size=(img_height, img_width),\n    batch_size=batch_size,\n    shuffle=False\n)\n\n# Convert TensorFlow dataset to NumPy arrays\ndef dataset_to_numpy(dataset):\n    images = []\n    labels = []\n    for image_batch, label_batch in dataset:\n        images.append(image_batch.numpy())  # Convert tensors to numpy\n        labels.append(label_batch.numpy())\n\n    return np.concatenate(images), np.concatenate(labels)\n\n# Extract x_train, y_train, x_test, y_test\nx_train, y_train = dataset_to_numpy(train_dataset)\nx_test, y_test = dataset_to_numpy(test_dataset)\n\n# Normalize images (optional)\nx_train = x_train / 255.0\nx_test = x_test / 255.0\n\nprint(f\"x_train shape: {x_train.shape}, y_train shape: {y_train.shape}\")\nprint(f\"x_test shape: {x_test.shape}, y_test shape: {y_test.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T15:20:35.828383Z","iopub.execute_input":"2025-04-01T15:20:35.828598Z","iopub.status.idle":"2025-04-01T15:20:50.520127Z","shell.execute_reply.started":"2025-04-01T15:20:35.828577Z","shell.execute_reply":"2025-04-01T15:20:50.519326Z"}},"outputs":[{"name":"stdout","text":"Found 1963 files belonging to 7 classes.\nFound 563 files belonging to 7 classes.\nx_train shape: (1963, 224, 224, 3), y_train shape: (1963,)\nx_test shape: (563, 224, 224, 3), y_test shape: (563,)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, Dense, LSTM, Reshape\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Assuming x_train is of shape (num_samples, height, width, channels)\n# Define input shape\nheight, width, channels = x_train.shape[1], x_train.shape[2], x_train.shape[3]\nnum_classes = len(set(y_train))  # Dynamically set number of classes\n\n# Data Augmentation\ndatagen = ImageDataGenerator(\n)\n\n# Define the model\ninput_layer = Input(shape=(height, width, channels))\n\n# CNN Feature Extractor\nx = Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\")(input_layer)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)  # Increased dropout\n\nx = Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\")(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Dropout(0.3)(x)  # Increased dropout\n\n# Flatten the output from CNN before passing to LSTM\nx = Flatten()(x)\n\n# Reshape the output to be compatible with LSTM\nx = Reshape((1, -1))(x)  # Reshape to (batch_size, 1, features)\n\n# LSTM Layer\nx = LSTM(32, return_sequences=False)(x)  # Reduced LSTM units\n\n# Dropout Layer\nx = Dropout(0.3)(x)  # Increased dropout\n\n# Batch Normalization\nx = BatchNormalization()(x)\n\n# Output Layer\noutput_layer = Dense(num_classes, activation=\"softmax\")(x)\n\n# Create the model\ncnn_lstm_model = Model(inputs=input_layer, outputs=output_layer)\n\n# Compile the model\ncnn_lstm_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.000001),  # Adjusted learning rate\n                        loss=\"sparse_categorical_crossentropy\",\n                        metrics=[\"accuracy\"])\n\n# Early Stopping\nearly_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n\n# Train the model with data augmentation\nhistory = cnn_lstm_model.fit(datagen.flow(x_train, y_train, batch_size=8),  # Use data generator\n                              validation_data=(x_test, y_test),\n                              epochs=50,\n                              callbacks=[early_stopping])  # Added early stopping\n\n# Evaluate the model\ntest_loss, test_acc = cnn_lstm_model.evaluate(x_test, y_test)\nprint(f\"Test Accuracy: {test_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T15:20:50.521164Z","iopub.execute_input":"2025-04-01T15:20:50.521478Z","iopub.status.idle":"2025-04-01T15:29:49.618242Z","shell.execute_reply.started":"2025-04-01T15:20:50.521447Z","shell.execute_reply":"2025-04-01T15:29:49.617387Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 50ms/step - accuracy: 0.1617 - loss: 2.3178 - val_accuracy: 0.2771 - val_loss: 1.9061\nEpoch 2/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.2294 - loss: 1.9315 - val_accuracy: 0.3748 - val_loss: 1.7712\nEpoch 3/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.2958 - loss: 1.7802 - val_accuracy: 0.6146 - val_loss: 1.5207\nEpoch 4/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.3719 - loss: 1.6456 - val_accuracy: 0.6465 - val_loss: 1.3480\nEpoch 5/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4483 - loss: 1.5021 - val_accuracy: 0.7282 - val_loss: 1.2159\nEpoch 6/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.4785 - loss: 1.4309 - val_accuracy: 0.7460 - val_loss: 1.1397\nEpoch 7/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5155 - loss: 1.3240 - val_accuracy: 0.8259 - val_loss: 1.0522\nEpoch 8/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.5838 - loss: 1.1955 - val_accuracy: 0.8224 - val_loss: 0.9708\nEpoch 9/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.6365 - loss: 1.0731 - val_accuracy: 0.8632 - val_loss: 0.9291\nEpoch 10/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.6610 - loss: 1.0475 - val_accuracy: 0.8526 - val_loss: 0.8929\nEpoch 11/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.6997 - loss: 0.9502 - val_accuracy: 0.8739 - val_loss: 0.8490\nEpoch 12/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7072 - loss: 0.8968 - val_accuracy: 0.9023 - val_loss: 0.7996\nEpoch 13/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7349 - loss: 0.8466 - val_accuracy: 0.9059 - val_loss: 0.7805\nEpoch 14/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7397 - loss: 0.8312 - val_accuracy: 0.9165 - val_loss: 0.7600\nEpoch 15/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7740 - loss: 0.7512 - val_accuracy: 0.9130 - val_loss: 0.7507\nEpoch 16/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7686 - loss: 0.7444 - val_accuracy: 0.9183 - val_loss: 0.7467\nEpoch 17/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.8135 - loss: 0.6658 - val_accuracy: 0.9307 - val_loss: 0.7251\nEpoch 18/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.8115 - loss: 0.6508 - val_accuracy: 0.9325 - val_loss: 0.7128\nEpoch 19/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.8094 - loss: 0.6508 - val_accuracy: 0.9432 - val_loss: 0.6789\nEpoch 20/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.8252 - loss: 0.6440 - val_accuracy: 0.9574 - val_loss: 0.6487\nEpoch 21/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.8302 - loss: 0.5854 - val_accuracy: 0.9485 - val_loss: 0.6541\nEpoch 22/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.8443 - loss: 0.5430 - val_accuracy: 0.9627 - val_loss: 0.6256\nEpoch 23/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.8374 - loss: 0.5505 - val_accuracy: 0.9645 - val_loss: 0.6194\nEpoch 24/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.8725 - loss: 0.5099 - val_accuracy: 0.9449 - val_loss: 0.6401\nEpoch 25/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.8738 - loss: 0.5070 - val_accuracy: 0.9663 - val_loss: 0.5881\nEpoch 26/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.8818 - loss: 0.4740 - val_accuracy: 0.9663 - val_loss: 0.5877\nEpoch 27/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.8810 - loss: 0.4829 - val_accuracy: 0.9663 - val_loss: 0.5676\nEpoch 28/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9061 - loss: 0.4336 - val_accuracy: 0.9716 - val_loss: 0.5644\nEpoch 29/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.8953 - loss: 0.4253 - val_accuracy: 0.9787 - val_loss: 0.5452\nEpoch 30/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9011 - loss: 0.4277 - val_accuracy: 0.9751 - val_loss: 0.5425\nEpoch 31/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9028 - loss: 0.4173 - val_accuracy: 0.9769 - val_loss: 0.5302\nEpoch 32/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.9114 - loss: 0.3833 - val_accuracy: 0.9680 - val_loss: 0.5376\nEpoch 33/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9034 - loss: 0.4000 - val_accuracy: 0.9751 - val_loss: 0.5159\nEpoch 34/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9242 - loss: 0.3702 - val_accuracy: 0.9751 - val_loss: 0.5086\nEpoch 35/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9269 - loss: 0.3681 - val_accuracy: 0.9876 - val_loss: 0.4859\nEpoch 36/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.9350 - loss: 0.3294 - val_accuracy: 0.9787 - val_loss: 0.4981\nEpoch 37/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9162 - loss: 0.3608 - val_accuracy: 0.9876 - val_loss: 0.4642\nEpoch 38/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9331 - loss: 0.3253 - val_accuracy: 0.9840 - val_loss: 0.4608\nEpoch 39/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9313 - loss: 0.3435 - val_accuracy: 0.9911 - val_loss: 0.4391\nEpoch 40/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9318 - loss: 0.3317 - val_accuracy: 0.9876 - val_loss: 0.4346\nEpoch 41/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9324 - loss: 0.3293 - val_accuracy: 0.9893 - val_loss: 0.4193\nEpoch 42/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9380 - loss: 0.3273 - val_accuracy: 0.9911 - val_loss: 0.4187\nEpoch 43/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9389 - loss: 0.3063 - val_accuracy: 0.9876 - val_loss: 0.4110\nEpoch 44/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9452 - loss: 0.2959 - val_accuracy: 0.9893 - val_loss: 0.4021\nEpoch 45/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9450 - loss: 0.3026 - val_accuracy: 0.9893 - val_loss: 0.3914\nEpoch 46/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 42ms/step - accuracy: 0.9377 - loss: 0.3004 - val_accuracy: 0.9858 - val_loss: 0.4003\nEpoch 47/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9581 - loss: 0.2744 - val_accuracy: 0.9911 - val_loss: 0.3754\nEpoch 48/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9417 - loss: 0.2698 - val_accuracy: 0.9911 - val_loss: 0.3710\nEpoch 49/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9538 - loss: 0.2677 - val_accuracy: 0.9911 - val_loss: 0.3580\nEpoch 50/50\n\u001b[1m246/246\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.9491 - loss: 0.2845 - val_accuracy: 0.9929 - val_loss: 0.3567\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9867 - loss: 0.4002\nTest Accuracy: 0.9929\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Save the model in .h5 format\ncnn_lstm_model.save(\"/kaggle/working/speech_emotion_model1.h5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-01T15:37:43.249081Z","iopub.execute_input":"2025-04-01T15:37:43.249339Z","iopub.status.idle":"2025-04-01T15:37:44.250416Z","shell.execute_reply.started":"2025-04-01T15:37:43.249317Z","shell.execute_reply":"2025-04-01T15:37:44.249415Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}